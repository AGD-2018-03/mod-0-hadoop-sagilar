{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recuerde no agregar o quitar celdas en este notebook, ni modificar su tipo. Si lo hace, el sistema automaticamente lo calificará con cero punto cero (0.0)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenga la cantidad de registros por letra para el siguiente archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile input.txt\nB   1999-08-28   14\nE   1999-12-06   12\nE   1993-07-21   17\nC   1991-02-12   13\nE   1995-04-25   16\nA   1992-08-22   14\nB   1999-06-11   12\nE   1993-01-27   13\nE   1999-09-10   11\nE   1990-05-03   16\nE   1994-02-14   10\nA   1988-04-27   12\nA   1990-10-06   10\nE   1985-02-12   16\nE   1998-09-14   16\nB   1994-08-30   17\nA   1997-12-15   13\nB   1995-08-23   10\nB   1998-11-22   13\nB   1997-04-09   14\nE   1993-12-27   18\nE   1999-01-14   15\nA   1992-09-19   18\nB   1993-03-02   14\nB   1999-10-21   13\nA   1990-08-31   12\nC   1994-01-25   10\nE   1990-02-09   18\nA   1990-09-26   14\nA   1993-05-08   16\nB   1995-09-06   14\nE   1991-02-18   14\nA   1993-01-11   14\nA   1990-07-22   18\nC   1994-09-09   15\nC   1994-07-27   10\nD   1990-10-10   15\nA   1990-09-05   11\nB   1991-10-01   15\nA   1994-10-25   13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%writefile mapper.py\n",
    "#! /usr/bin/env python\n",
    "\n",
    "##\n",
    "## Esta es la función que mapea la entrada a parejas (clave, valor)\n",
    "##\n",
    "import sys\n",
    "\n",
    "\n",
    "##\n",
    "## Se usa una clase iterable para implementar el mapper.\n",
    "##\n",
    "\n",
    "class Mapper:\n",
    "    \n",
    "    def __init__(self, stream):\n",
    "        ## \n",
    "        ## almacena el flujo de entrada como una\n",
    "        ## variable del objeto\n",
    "        ##\n",
    "        self.stream = stream\n",
    "    \n",
    "    def emit(self, key, value):\n",
    "        ##\n",
    "        ## escribe al flujo estándar de salida\n",
    "        ##\n",
    "        sys.stdout.write(\"{}\\t{}\\n\".format(key, value))\n",
    "        \n",
    "    def map(self):\n",
    "\n",
    "        word_counter = 0\n",
    "        \n",
    "        for word in self:\n",
    "            \n",
    "            ##\n",
    "            ## imprime un mensaje indicando la palabra procesada\n",
    "            ##\n",
    "            #self.status('procesando ' + word)\n",
    "            \n",
    "            ##\n",
    "            ## cuenta la cantidad de palabras procesadas\n",
    "            ##\n",
    "            word_counter += 1\n",
    "            ##\n",
    "            ## por cada palabra del flujo de datos\n",
    "            ## emite la pareja (word, 1)\n",
    "            ##\n",
    "            self.emit(key=word, value=1)\n",
    "            \n",
    "    def __iter__(self):\n",
    "        ##\n",
    "        ## itera sobre cada linea de código recibida\n",
    "        ## a través del flujo de entrada\n",
    "        ##\n",
    "        for line in self.stream:\n",
    "            ##\n",
    "            ## itera sobre cada palabra de la línea\n",
    "            ## (en los ciclos for, retorna las palabras\n",
    "            ## una a una)\n",
    "            ##\n",
    "            yield line[0]\n",
    "            #for word in line.split():\n",
    "                ##\n",
    "                ## retorna la palabra siguiente en el\n",
    "                ## ciclo for\n",
    "                ##\n",
    "                #yield word\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    ##\n",
    "    ## inicializa el objeto con el flujo de entrada\n",
    "    ##\n",
    "    mapper = Mapper(sys.stdin)\n",
    "    \n",
    "    ##\n",
    "    ## ejecuta el mapper\n",
    "    ##\n",
    "    mapper.map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "class Reducer:\n",
    "    \n",
    "    def __init__(self, stream):\n",
    "        self.stream = stream\n",
    "        \n",
    "    def emit(self, key, value):\n",
    "        sys.stdout.write(\"{}\\t{}\\n\".format(key, value)) \n",
    "\n",
    "    def reduce(self):\n",
    "        ##\n",
    "        ## Esta función reduce los elementos que \n",
    "        ## tienen la misma clave\n",
    "        ##        \n",
    "        for key, group in itertools.groupby(self, lambda x: x[0]):\n",
    "            total = 0\n",
    "            for _, val in group:\n",
    "                total += val\n",
    "            \n",
    "            self.emit(key=key, value=total)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        for line in self.stream:\n",
    "            ##\n",
    "            ## Lee el stream de datos y lo parte \n",
    "            ## en (clave, valor)\n",
    "            ##\n",
    "            key, val = line.split(\"\\t\") \n",
    "            val = int(val)\n",
    "            \n",
    "            ##\n",
    "            ## retorna la tupla (clave, valor)\n",
    "            ## como el siguiente elemento del ciclo for\n",
    "            ##\n",
    "            yield (key, val)\n",
    "\n",
    "\n",
    "if __name__ == '__main__': \n",
    "  \n",
    "    reducer = Reducer(sys.stdin)\n",
    "    reducer.reduce()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\nrm -rf output\nSTREAM=$HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar\nchmod +x mapper.py\nchmod +x reducer.py\nhadoop jar $STREAM -input input.txt -output output  -mapper mapper.py -reducer reducer.py\ncat output/part-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf mapper.py reducer.py output input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar la evaluación automática de este libro:\n",
    "\n",
    "* Abra un Terminal.\n",
    "* Asegurece que esat en la misma carpeta que contiene este notebook.\n",
    "* Salve el notebook.\n",
    "* Ejecute el siguiente comando:\n",
    "\n",
    "      ./gradetool 05-Taller.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
